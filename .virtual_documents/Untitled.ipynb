import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.callbacks import Callback
from sklearn.model_selection import train_test_split
from tensorflow.keras.layers import Normalization


data = pd.read_csv('nutrilens.csv')
data


data.sort_values(by='Lemak (g)', ascending=False).groupby('Lemak (g)').head(20)


data[data['Grade'] == "C"]


data.columns = data.columns.str.lower().str.replace(" ","_")


data.columns


X = data[['energi_(kal)', 'protein_(g)', 'lemak_(g)','karbohidrat_(g)', 'serat_(g)', 'natrium_(mg)']].values
y = data['grade'].values


grade_mapping = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}
y_integers = np.array([grade_mapping[grade] for grade in y])
y = tf.one_hot(y_integers, depth=len(grade_mapping))
# Convert the one-hot encoded tensor to a NumPy array
y_one_hot_array = y.numpy()

# Now you can use train_test_split with the NumPy array
X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot_array, test_size=0.2, random_state=42)



normalizer = Normalization(axis=-1)
normalizer.adapt(X_train)
# Define a custom callback to stop training when MAE < 2
class CustomCallback(Callback):
    def on_epoch_end(self, epoch, logs=None):
        if logs.get('val_accuracy') > 0.91:
            print("\\val_accuracy has reached above 90,% so stopping training.")
            self.model.stop_training = True

# Create the model
model = Sequential([
    normalizer,
    # Add layers according to your specific problem
    Dense(256,activation='relu'),
    Dense(128, activation='relu'),  # Replace 'input_shape' with your data's input shape
    Dense(64, activation='relu'),
    Dense(5, activation='softmax')  # Output layer with 5 units for 5 classes
])

# Compile the model with cross-entropy loss function and an optimizer of your choice
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy', 'mae'])

# Instantiate the custom callback
callback = CustomCallback()

# Train the model with the callback
history = model.fit(X_train, y_train, 
                    validation_data=(X_test, y_test),
                    epochs=100000,  # Set a large number of epochs
                    callbacks=[callback])


# Plotting accuracy
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy vs. Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Plotting loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Loss vs. Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()


#['energi_(kal)', 'protein_(g)', 'lemak_(g)','karbohidrat_(g)', 'serat_(g)', 'natrium_(mg)']
#{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}

def output(energi, protein, lemak, karbohidrat, serat, natrium):
    input_data = np.array([[energi, protein, lemak, karbohidrat, serat, natrium]])
    predict = model.predict(input_data)
    predict = np.array2string(predict, formatter={'float_kind':'{0:.3f}'.format})
    
    return predict


#{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}
result = output(90, 2, 4, 12, 0, 220)
print(result)



